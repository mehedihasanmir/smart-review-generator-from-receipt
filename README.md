# ğŸ§¾ Smart Review Generator from Receipt

<div align="center">

**Facilitating the automated conversion of unstructured receipt data into authentic, human-centric product reviews.**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-green)](https://openai.com/)
[![LangChain](https://img.shields.io/badge/LangChain-Orchestration-blueviolet)](https://langchain.com/)

</div>

---

## ğŸ“– Overview

Smart Review Generator is a modular, artificially intelligent Command Line Interface (CLI) application designed to automate the product review workflow. This system mitigates the friction associated with drafting detailed feedback by recontextualizing the user experience as a conversational interaction. Through the ingestion of receipt data, the application verifies purchase context, generates dynamic, context-sensitive inquiry protocols, and synthesizes naturalistic reviews utilizing LangChain and OpenAI.

In contrast to conventional generative tools that yield grammatically impeccable yet discernibly artificial text, this system is specifically engineered to emulate the nuances of human communication. It is architected to introduce specific linguistic variances, colloquial phrasing, and personal contextâ€”elements frequently absent in standard language models.



## ğŸ“‹ Table of Contents

- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Project Structure](#-project-structure)
- [Installation & Setup](#-installation--setup-procedures)
- [Usage Instructions](#-usage-instructions)
- [Operational Demonstration](#-operational-demonstration)
- [Strategies for Authenticity Preservation](#-strategies-for-authenticity-preservation)
- [Contributing](#-contribution-guidelines)
- [License](#-license)

## ğŸš€ Key Features

### Intelligent Data Parsing
Ingests and analyzes receipt data (JSON or raw text) to extract structured product information.  
The system performs structural analysis to identify specific line items, associate brands with products, and extract pricing schemas. This establishes a verifiable chain of custody for the data, ensuring that every generated review is anchored to a purchase event context, thereby eliminating fraudulent submissions and enhancing credibility.

### Context-Sensitive Dynamic Inquiry Generation
Departing from static survey methodologies, the system employs a Large Language Model (LLM) to generate unique, non-repetitive interview queries.  
The application analyzes product metadata (e.g., differentiating between "Skincare" and "Consumer Goods") to formulate relevant lines of inquiry. For instance, the system queries regarding "texture and absorption" for dermatological products, while inquiring about "flavor profile and texture" for food items.

### Natural Language Generation (NLG) with Human-Centric Constraints
Leverages advanced prompt engineering techniques with strict "negative constraints" to filter out AI hallucinations and superfluous marketing terminology.  
The generation engine is calibrated to prioritize linguistic entropy and variability. By actively diversifying sentence structures, incorporating casual contractions, and mimicking natural typing patterns, the system ensures the review reads authenticallyâ€”simulating text composed by a human user on a mobile device, rather than output generated by a centralized server.

### Weighted Sentiment Analysis and Response Weighting
The system evaluates not only the content of the user's response but also the manner of expression.  
Responses characterized by greater length and enthusiasm are assigned higher weight coefficients (e.g., 1.5x), thereby influencing the tone of the final review more significantly than brief, utilitarian responses.

### Modular Architecture for Scalability and Extensibility
The application is architected upon the "Separation of Concerns" principle. The Data Ingestion, AI Logic, Data Management, and UI layers are decoupled, facilitating the seamless substitution of components (e.g., migrating LLM backends) without necessitating a comprehensive refactor of the codebase.

---

## ğŸ› ï¸ System Architecture

The system adheres to a rigorous, linear data pipeline designed to ensure robust error handling and data integrity:

### 1. Data Ingestion and Validation
The user supplies a file path to the receipt data (JSON/Text). The system subsequently validates the file format and verifies its existence.

### 2. Data Processing Layer
The system processes the raw input data to extract semantic lines, filtering out extraneous noise (headers, footers, tax information) to isolate product identifiers.

### 3. Eligibility Verification and Filtering Logic
product_logic.py cross-references the extracted items against review_history.json. It enforces a 90-day cooldown period to preclude duplicate reviews for the identical Stock Keeping Unit (SKU), ensuring diversity within the review history.

### 4. AI Interrogation Phase
ai_engine.py initializes a LangChain instance. It supplies the product context to the OpenAI API to generate 4-5 bespoke inquiries.

### 5. Interactive User Feedback Mechanism
The CLI (ui_handler.py) presents these inquiries to the user sequentially. It captures both the textual response and the associated metadata (word count, keywords) for subsequent weighting.

### 6. Synthesis and Generation
The engine compiles the weighted conversation history. It constructs a complex prompt that synthesizes the user's specific insights with a selected "Tone Style" (e.g., Casual, Enthusiastic) to generate the final textual output.

---

## ğŸ“‚ Project Structure
```bash
The following directory structure outlines the organization of the codebase:

smart-review-generator-from-receipt/
â”‚
â”œâ”€â”€ .env                  # Environment secrets (OpenAI API Key)
â”œâ”€â”€ main.py               # Orchestrator: Connects UI, Data, and AI modules together
â”œâ”€â”€ config.py             # Configuration hub: Tone definitions, category logic, and prompt templates
â”œâ”€â”€ data_manager.py       # Handles JSON file I/O, error proofing, and history persistence
â”œâ”€â”€ product_logic.py      # Business logic: Determines which products are eligible for review
â”œâ”€â”€ ai_engine.py          # The Core Brain: Contains LangChain chains for Q&A and Generation
â””â”€â”€ ui_handler.py         # CLI: Manages print statements, inputs, and error messaging
```
---

## ğŸ› ï¸ System Architecture

The system adheres to a rigorous, linear data pipeline designed to ensure robust error handling and data integrity:

**Data Ingestion and Validation:** The user supplies a file path to the receipt data (JSON/Text). The system subsequently validates the file format and verifies its existence.

**Data Processing Layer:** The system processes the raw input data to extract semantic lines, filtering out extraneous noise (headers, footers, tax information) to isolate product identifiers.

**Eligibility Verification and Filtering Logic:** `product_logic.py` cross-references the extracted items against `review_history.json`. It enforces a 90-day cooldown period to preclude duplicate reviews for the identical Stock Keeping Unit (SKU), ensuring diversity within the review history.

**AI Interrogation Phase:** `ai_engine.py` initializes a LangChain instance. It supplies the product context to the OpenAI API to generate 4-5 bespoke inquiries.

**Interactive User Feedback Mechanism:** The CLI (`ui_handler.py`) presents these inquiries to the user sequentially. It captures both the textual response and the associated metadata (word count, keywords) for subsequent weighting.

**Synthesis and Generation:** The engine compiles the weighted conversation history. It constructs a complex prompt that synthesizes the user's specific insights with a selected "Tone Style" (e.g., Casual, Enthusiastic) to generate the final textual output.


## ğŸ–¥ï¸ Usage Instructions

The application is deployed as a command-line interface (CLI) tool and supports two modes of execution:

**1. Direct Execution Mode**  
Provide the file path as an argument for immediate processing:

```bash
python main.py path/to/receipt_data.json
```

Interactive Execution Mode: Execute the script without arguments to initiate a prompt for the file location.

```bash
python main.py
```

## âœ¨ Operational Demonstration

The following section illustrates how a transaction is transformed into a polished review.

**1. Input Data Specification**

**Data Extraction:**  
The system identifies a transaction at Whole Foods Market and parses the following line item:

- **Item:** Olipop Vintage Cola  
- **Price:** $2.49

**2. User-System Interaction Protocol (AI â†” User)**

The AI classifies the item as "Beverage" and interacts in a casual, inquisitive manner:

```bash
ğŸ“ Enter path to receipt JSON file: C:\Users\username\Desktop\folder \test.json
Welcome to the SMART REVIEW SYSTEM

ğŸ¤– AI: How does the soft cotton blend of this Champion hoodie contribute to its comfort?
ğŸ‘¤ You: it's very comfortable

ğŸ¤– AI: Can the adjustable drawstring hood on this hoodie provide a snug fit for different head sizes?
ğŸ‘¤ You: yeah the hood is adjustable 

ğŸ¤– AI: Is the front kangaroo pocket on the Champion hoodie spacious enough to carry essential items?
ğŸ‘¤ You: no parsonally i don't like it, case it destroy shape after using few days

ğŸ¤– AI: Given its warm and comfortable feature, would this medium-sized black Champion hoodie be suitable for colder climates?
ğŸ‘¤ You: yes

ğŸ¤– AI: Finally, how would you rate it from 1â€“5 stars?
ğŸ‘¤ You (1-5): 4
```


**3. Generated Output Artifact (Final Review)**

- **Parameters:** 5 Stars | Tone: Casual | Length: Short  
- The system emphasizes high-weight responses to generate an authentic, casual review.

ğŸ“ **GENERATED REVIEW:**

```bash
ğŸ”„ Generating your review...

GENERATED REVIEW:

This Champion hoodie? Yeah, it's very comfortable. The soft cotton blend really makes a difference, especially when it's cold out. The hood? It's adjustable, fits different head sizes no problem. Only issue is with the front pocket. Personally, I don't like it much. In my case, it seemed to lose its shape after a few days. But still, overall, it's a solid hoodie. Definitely worth keeping this stocked.

â­ Rating: 4/5 stars
```

## ğŸ›¡ï¸ Strategies for Authenticity Preservation

AI-generated content often suffers from the 'Uncanny Valley' effectâ€”text that is grammatically correct but emotionally flat and obviously synthetic. To mitigate this and maintain authenticity, `ai_engine.py` enforces **Negative Constraints** within the system prompt architecture. These act as guardrails, preventing the model from reverting to generic marketing patterns.

The model is explicitly instructed **NOT** to use:

- âŒ **Corporate Connectors:** Phrases like "In conclusion," "Moreover," "To summarize," or "It is worth noting."
- âŒ **Marketing Superlatives:** Terms such as "Game-changer," "Innovative," "Premium," or "Elevating."
- âŒ **Formal Phrasing:** Phrases like "I recently purchased" are replaced with casual alternatives like "I picked up" or "I grabbed."
- âŒ **Meta-References:** Star ratings are never mentioned directly within the review body (e.g., "I give this 5 stars"), as real users rarely do this.

This approach ensures generated reviews feel natural and integrate seamlessly with authentic user-generated content.

## ğŸ¤ Contribution Guidelines

Contributions are welcome! You can help by adding support for new data formats, optimizing prompt engineering, or implementing a GUI.

**Steps to Contribute:**

1. Fork the repository.  
2. Create a feature branch:  
   ```bash
   git checkout -b feature/AmazingFeature
   ```

3. Commit your changes:
    ```bash
    git commit -m "Add some AmazingFeature"
    ```
4. Push to your branch:
    ```bash
    git push origin feature/AmazingFeature
    ```
5. Open a Pull Request.

## ğŸ“„ License

Distributed under the MIT License. Refer to LICENSE for further details.


